{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual rendering notebook\n",
    "\n",
    "The goal of this notebook is to provide visual rendering of data using Kepler.gl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global variables\n",
    "\n",
    "# Setting up the Coordinate Reference Systems up front in the necessary format.\n",
    "crs_degree = {'init': 'epsg:4326'} # CGS_WGS_1984 (what the GPS uses)\n",
    "\n",
    "# --- Paths\n",
    "\n",
    "# Root path of Fremont Dropbox\n",
    "import os\n",
    "import sys\n",
    "# We let this notebook to know where to look for fremontdropbox module\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from fremontdropbox import get_dropbox_location\n",
    "# Root path of the Dropbox business account\n",
    "dbx = get_dropbox_location()\n",
    "\n",
    "# Temporary! Location of the folder where the restructuring is currently happening\n",
    "data_path = dbx + '/Private Structured data collection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gdf(path):\n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "        path: path of the file to read as a geodataframe\n",
    "        \n",
    "    return:\n",
    "        a GeoDataFrame (with Geopandas) corresponding to the file path\n",
    "    \"\"\"\n",
    "    gdf = gpd.GeoDataFrame.from_file(path)\n",
    "    gdf = gdf.to_crs('epsg:4326')\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "config_file = open('visualization_config.txt', 'r')\n",
    "text = config_file.read()\n",
    "dict_config = ast.literal_eval(text)\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Network data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project delimitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Type                                           geometry\n",
      "0  Delimitation  POLYGON ((-121.94277 37.55273, -121.94100 37.5...\n",
      "1           Box  POLYGON ((-121.95676 37.48510, -121.95676 37.5...\n",
      "  Type                                           geometry\n",
      "1  Box  POLYGON ((-121.95676 37.48510, -121.95676 37.5...\n",
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afeca6940fe04f3fbbaf00fefd3384fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'Project box delimitation': {'index': [1], 'columns': ['Type', 'geometry'], 'data': [['Box', 'Pâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project_del_path = dbx + \"/Private Structured data collection/Manual-made dataset (do not touch)/Network/Map/Project Delimitation/Project_delimitation.shp\"\n",
    "project_del = to_gdf(project_del_path)\n",
    "\n",
    "fremont_map = KeplerGl(height=600)\n",
    "fremont_map.add_data(data = project_del[project_del.Type == \"Box\"], name=\"Project box delimitation\")\n",
    "fremont_map.add_data(data = project_del[project_del.Type == \"Delimitation\"], name=\"Project delimitation\")\n",
    "fremont_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aimsun map\n",
    "\n",
    "## To do Theo: get new network data from Aimsun and plot with new data when every works (centroids, centroid connections, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "/Users/theophile/Dropbox/Private Structured data collection/Aimsun/Inputs_wk_26_OD_4_12_2020/detectors.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: /Users/theophile/Dropbox/Private Structured data collection/Aimsun/Inputs_wk_26_OD_4_12_2020/detectors.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3e1812270ae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maimsun_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maimsun_path_complex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdetectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_gdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maimsun_path\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'detectors.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmeterings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_gdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maimsun_path\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'meterings.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_gdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maimsun_path\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'centroids.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1d61731d9c93>\u001b[0m in \u001b[0;36mto_gdf\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mGeoDataFrame\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mwith\u001b[0m \u001b[0mGeopandas\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mgdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epsg:4326'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.7/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, filename, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nybb.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.7/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.7/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.7/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0;32m--> 254\u001b[0;31m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.7/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: /Users/theophile/Dropbox/Private Structured data collection/Aimsun/Inputs_wk_26_OD_4_12_2020/detectors.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "aimsun_path_regular = dbx + '/Private Structured data collection/Aimsun/Inputs/'\n",
    "aimsun_path_complex = dbx + '/Private Structured data collection/Aimsun/Inputs_wk_26_OD_4_12_2020/'\n",
    "\n",
    "aimsun_path = aimsun_path_complex\n",
    "\n",
    "detectors = to_gdf(aimsun_path +'detectors.shp')\n",
    "meterings = to_gdf(aimsun_path +'meterings.shp')\n",
    "centroids = to_gdf(aimsun_path +'centroids.shp')\n",
    "centroid_connections = to_gdf(aimsun_path +'centroid_connections.shp')\n",
    "nodes = to_gdf(aimsun_path +'nodes.shp')\n",
    "# polygons = to_gdf(aimsun_path +'polygons.shp')\n",
    "sections = to_gdf(aimsun_path +'sections.shp')\n",
    "sectionsGeo = to_gdf(aimsun_path +'sectionsGeo.shp')\n",
    "turnings = to_gdf(aimsun_path +'turnings.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following cell is useful to better understand and render the network\n",
    "## To do Theo: get the different screenshot of the section characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-571029c675cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fremont_map = KeplerGl(height=600)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnode_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodetype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------Nodes-------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nodes' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# fremont_map = KeplerGl(height=600)\n",
    "\n",
    "node_type = np.sort(nodes.nodetype.unique())\n",
    "print(\"--------Nodes-------\")\n",
    "print()\n",
    "print(\"Total number of nodes: \" + str(nodes['id'].count()))\n",
    "print(\"Nodes type values: \" + str(node_type))\n",
    "for i in node_type:\n",
    "    print(\"Number of nodes with type \" + str(i) + \": \" + str(nodes[nodes['nodetype'] == i]['id'].count()))\n",
    "    if False:\n",
    "        fremont_map.add_data(data = nodes[nodes['nodetype'] == i], name=\"Nodes type \" + str(i))\n",
    "\n",
    "    \n",
    "print()\n",
    "print(\"------Sections------\")\n",
    "\n",
    "print(\"Total number of section: \" + str(sections['id'].count()))\n",
    "print()\n",
    "section_type = np.sort(sections.rd_type.unique())\n",
    "print(\"Road type values: \" + str(section_type))\n",
    "print(\"175 = Motorway, 177 = Primary, 179 = Residential, 180 = Secondary, 182.0 = Tertiary, 184.0 = Trunk, 185.0 = Unclassified\")\n",
    "for i in section_type:\n",
    "    print(\"Number of sections with type \" + str(i) + \": \" + str(sections[sections['rd_type'] == i]['id'].count()))\n",
    "    if False:\n",
    "        fremont_map.add_data(data = sections[sections['rd_type'] == i], name=\"Sections type \" + str(i))\n",
    "    \n",
    "print()\n",
    "section_speed = np.sort(sections.speed.unique())\n",
    "print(\"Speed values: \" + str(section_speed))\n",
    "for i in section_speed:\n",
    "    print(\"Number of sections with speed \" + str(i) + \" (km/h): \" + str(sections[sections['speed'] == i]['id'].count()))\n",
    "    if False:\n",
    "        fremont_map.add_data(data = sections[sections['speed'] == i], name=\"Sections speed \" + str(i))\n",
    "\n",
    "print()\n",
    "section_cap = np.sort(sections.capacity.unique())\n",
    "print(\"Capacity values: \" + str(section_cap))\n",
    "for i in section_cap:\n",
    "    print(\"Number of sections with capacity \" + str(i) + \" (veh/h): \" + str(sections[sections['capacity'] == i]['id'].count()))\n",
    "    if False:\n",
    "        fremont_map.add_data(data = sections[sections['capacity'] == i], name=\"Sections capacity \" + str(i))\n",
    "    \n",
    "print()\n",
    "section_func = np.sort(sections.func_class.unique())\n",
    "print(\"Function class values: \" + str(section_func))\n",
    "for i in section_func:\n",
    "    print(\"Number of sections with function class \" + str(i) + \": \" + str(sections[sections['func_class'] == i]['id'].count()))\n",
    "    if False:\n",
    "        fremont_map.add_data(data = sections[sections['func_class'] == i], name=\"Sections function class \" + str(i))\n",
    "    \n",
    "# fremont_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid_config = centroid_map.config\n",
    "# file.write(\",'centroid_config': \" + str(centroid_config))\n",
    "# file.write(\"}\")\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0724882c56124b6eafd391737caf76ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'Detectors': {'index': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fremont_map = KeplerGl(height=600)\n",
    "fremont_map.add_data(data = detectors, name=\"Detectors\")\n",
    "fremont_map.add_data(data = meterings, name=\"meterings\")\n",
    "fremont_map.add_data(data = nodes, name=\"nodes\")\n",
    "# fremont_map.add_data(data = polygons, name=\"polygons\")\n",
    "fremont_map.add_data(data = sections, name=\"sections\")\n",
    "fremont_map.add_data(data = sectionsGeo, name=\"sectionsGeo\")\n",
    "fremont_map.add_data(data = turnings, name=\"turnings\")\n",
    "fremont_map.add_data(data = centroids, name=\"centroids\")\n",
    "fremont_map.add_data(data = centroid_connections, name=\"centroid_connections\")\n",
    "fremont_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aimsun centroids and centroids connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dec92d54f644995b17faf466808ea12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'External centroids': {'index': [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107], 'columns'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "centroid_map = KeplerGl(height=600, config=dict_config['centroid_config'])\n",
    "centroid_map.add_data(data = centroids[centroids['name'].str.contains('ext')], name=\"External centroids\")\n",
    "centroid_map.add_data(data = centroids[centroids['name'].str.contains('int')], name=\"Internal centroids\")\n",
    "centroid_map.add_data(data = centroid_connections, name=\"Centroid connections\")\n",
    "# fremont_map.add_data(data = centroid_connections[centroid_connections['direction'] == 'from'], name=\"Outgoing centroid connections\")\n",
    "# fremont_map.add_data(data = centroid_connections[centroid_connections['direction'] == 'to'], name=\"Incoming centroid connections\")\n",
    "centroid_map.add_data(data = sections, name=\"sections\")\n",
    "centroid_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aimsun road section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4223323cfc664782937b3515d6243d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [], 'layers': [{'id': 'cmvn55k', 'type': â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "road_section_map = KeplerGl(height=600, config=dict_config['road_type_config'])\n",
    "\n",
    "road_section_map.add_data(data = sections[sections['rd_type'] == 175.0], name=\"Motorway\")\n",
    "road_section_map.add_data(data = sections[sections['rd_type'] == 177.0], name=\"Primary\")\n",
    "road_section_map.add_data(data = sections[sections['rd_type'] == 179.0], name=\"Residential\")\n",
    "road_section_map.add_data(data = sections[sections['rd_type'] == 180.0], name=\"Secondary\")\n",
    "road_section_map.add_data(data = sections[sections['rd_type'] == 182.0], name=\"Tertiary\")\n",
    "road_section_map.add_data(data = sections[sections['rd_type'] == 184.0], name=\"Trunk\")\n",
    "road_section_map.add_data(data = sections[sections['rd_type'] == 185.0], name=\"Unclassified\")\n",
    "\n",
    "road_section_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# road_type_config = road_section_map.config\n",
    "# file = open(\"visualization_config.txt\", 'w')\n",
    "# file.write(\"{'road_type_config': \" + str(road_type_config))\n",
    "# file.write(\"}\")\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic signals and stop signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gdf_csv(path):\n",
    "# https://geopandas.readthedocs.io/en/latest/gallery/create_geopandas_from_pandas.html#from-wkt-format\n",
    "    df = pd.read_csv(path)\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df, crs='epsg:4326', geometry=gpd.points_from_xy(df.x, df.y))\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_infra_path = data_path + \"/Manual-made dataset (do not touch)/Network/Infrastructure/\"\n",
    "\n",
    "stop_signs = to_gdf_csv(network_infra_path + \"Stop signs location/Stop_Signs.csv\")\n",
    "traffic_lights = to_gdf_csv(network_infra_path + \"Traffic lights location/Traffic_Lights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d535f26c68940d78da721592b2afb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'Stop signs': {'index': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fremont_map = KeplerGl(height=600)\n",
    "fremont_map.add_data(data = stop_signs, name=\"Stop signs\")\n",
    "fremont_map.add_data(data = traffic_lights, name=\"Traffic lights\")\n",
    "fremont_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop signs: 313\n",
      "Number of traffic lights: 123\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of stop signs: \" + str(stop_signs.__OBJECTID.count()))\n",
    "print(\"Number of traffic lights: \" + str(traffic_lights.__OBJECTID.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Demand data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transportation Analysis Zones\n",
    "\n",
    "## To do Ayush: \n",
    "1. Use the external centroids (and not centroid of the external TAZs) to plot the desire lines. Put in red external demand. Put in blue internal demand. Maybe cluster some internal TAZs together to get a better rendering of the demand data. Set the width of the lines to be a function of the lines. If possible get some legend about how width is related to count.\n",
    "2. Get the following information:\n",
    "    - Between 2 and 8pm: YYY residential cars (YYY = sum of count over every row of internal_od when dt_15 is between 14:00 and 20:00)\n",
    "    - Between 2 and 8pm: ZZZ traveler cars (ZZZ = sum of count over every row of external_od when dt_15 is between 14:00 and 20:00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Vehicles Analyzed at 6 PM (Internal): 3262\n",
      "Number of Vehicles Analyzed at 6 PM (External): 1263\n",
      "Number of Vehicles Analyzed at 6 PM (Total): 4525\n",
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfremont_map.save_to_html(file_name=data_path+\"/Data processing/Kepler maps/Demand/6pm_demand_map.html\")\\nfrm_config = fremont_map.config\\nfrm_map = KeplerGl(height=600, config=frm_config)\\nfrm_map.add_data(data = external_demand, name=\"External/External Demand\")\\nfrm_map.add_data(data = internal_demand, name=\"Internal/Internal Demand\")\\nfrm_map.add_data(data = internal_external_demand, name=\"Internal/External Demand\")\\nfrm_map.add_data(data = internal_taz, name=\"Internal TAZs\")\\nfrm_map.add_data(data = external_taz, name=\"External TAZs\")\\nfrm_map\\nfrm_map.save_to_html(file_name=data_path+\"/Data processing/Kepler maps/Demand/6pm_demand_count_widths_map.html\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "path_taz = data_path + \"/Data processing/Auxiliary files/Demand/OD demand/TAZ\"\n",
    "internal_taz = to_gdf(path_taz + \"/Internal_TAZ.shp\")\n",
    "external_taz = to_gdf(path_taz + \"/External_TAZ.shp\")\n",
    "\n",
    "# Get gravity centers for all TAZs (internal and external)\n",
    "centroid_gravity = {}\n",
    "for i in range(len(internal_taz['geometry'])):\n",
    "    centroid_gravity[internal_taz['CentroidID'][i]] = internal_taz['geometry'][i].centroid\n",
    "for i in range(len(external_taz['geometry'])):\n",
    "    centroid_gravity[external_taz['CentroidID'][i]] = external_taz['geometry'][i].centroid\n",
    "\n",
    "od_demand_path = data_path + \"/Data processing/Temporary exports to be copied to processed data/Demand/OD demand/\" \n",
    "internal_od = pd.read_csv(od_demand_path + \"Internal OD grouped by timestamp.csv\")\n",
    "external_od = pd.read_csv(od_demand_path + \"External OD grouped by timestamp.csv\")\n",
    "\n",
    "# Remove centroids with no demand\n",
    "external_od = external_od[external_od[\"counts\"] != 0]\n",
    "internal_od = internal_od[internal_od[\"counts\"] != 0]\n",
    "internal_od = internal_od[internal_od[\"CentroidID_O\"] != \"int_16\"]\n",
    "internal_od = internal_od[internal_od[\"CentroidID_D\"] != \"int_16\"]\n",
    "internal_od = internal_od[internal_od[\"CentroidID_O\"] != \"int_62\"]\n",
    "internal_od = internal_od[internal_od[\"CentroidID_D\"] != \"int_62\"]\n",
    "# Fix analysis timestep at 6 PM\n",
    "internal_od_6_pm = internal_od[internal_od[\"dt_15\"]==\"18:00\"]\n",
    "external_od_6_pm = external_od[external_od[\"dt_15\"]==\"18:0\"]\n",
    "\n",
    "internal_od_6_pm = internal_od_6_pm.reset_index()\n",
    "external_od_6_pm = external_od_6_pm.reset_index()\n",
    "\n",
    "external_demand = gpd.GeoDataFrame(columns=['CentroidID_O', 'CentroidID_D', \"counts\", 'geometry'])\n",
    "for i in range(len(external_od_6_pm['CentroidID_O'])):\n",
    "    origin_id = external_od_6_pm['CentroidID_O'][i]\n",
    "    dest_id = external_od_6_pm['CentroidID_D'][i]\n",
    "    demand = external_od_6_pm['counts'][i]\n",
    "    external_demand.loc[i] = [origin_id, dest_id, demand, LineString([centroid_gravity[origin_id], centroid_gravity[dest_id]])]\n",
    "\n",
    "internal_demand = gpd.GeoDataFrame(columns=['CentroidID_O', 'CentroidID_D', \"counts\", 'geometry'])\n",
    "internal_external_demand = gpd.GeoDataFrame(columns=['CentroidID_O', 'CentroidID_D', \"counts\", 'geometry'])\n",
    "for i in range(len(internal_od_6_pm['CentroidID_O'])):\n",
    "    origin_id = internal_od_6_pm['CentroidID_O'][i]\n",
    "    dest_id = internal_od_6_pm['CentroidID_D'][i]\n",
    "    demand = internal_od_6_pm['counts'][i]\n",
    "    if \"ext\" not in origin_id and \"ext\" not in dest_id:\n",
    "        internal_demand.loc[i] = [origin_id, dest_id, demand, LineString([centroid_gravity[origin_id], centroid_gravity[dest_id]])]\n",
    "    else:\n",
    "        internal_external_demand.loc[i] = [origin_id, dest_id, demand, LineString([centroid_gravity[origin_id], centroid_gravity[dest_id]])]\n",
    "\n",
    "print(\"Number of Vehicles Analyzed at 6 PM (Internal):\", internal_od_6_pm.counts.sum())\n",
    "print(\"Number of Vehicles Analyzed at 6 PM (External):\", external_od_6_pm.counts.sum())\n",
    "print(\"Number of Vehicles Analyzed at 6 PM (Total):\", internal_od_6_pm.counts.sum() + external_od_6_pm.counts.sum())\n",
    "\n",
    "fremont_map = KeplerGl(height=600)\n",
    "fremont_map.add_data(data = external_demand, name=\"External/External Demand\")\n",
    "fremont_map.add_data(data = internal_demand, name=\"Internal/Internal Demand\")\n",
    "fremont_map.add_data(data = internal_external_demand, name=\"Internal/External Demand\")\n",
    "fremont_map.add_data(data = internal_taz, name=\"Internal TAZs\")\n",
    "fremont_map.add_data(data = external_taz, name=\"External TAZs\")\n",
    "fremont_map\n",
    "\n",
    "'''\n",
    "fremont_map.save_to_html(file_name=data_path+\"/Data processing/Kepler maps/Demand/6pm_demand_map.html\")\n",
    "frm_config = fremont_map.config\n",
    "frm_map = KeplerGl(height=600, config=frm_config)\n",
    "frm_map.add_data(data = external_demand, name=\"External/External Demand\")\n",
    "frm_map.add_data(data = internal_demand, name=\"Internal/Internal Demand\")\n",
    "frm_map.add_data(data = internal_external_demand, name=\"Internal/External Demand\")\n",
    "frm_map.add_data(data = internal_taz, name=\"Internal TAZs\")\n",
    "frm_map.add_data(data = external_taz, name=\"External TAZs\")\n",
    "frm_map\n",
    "frm_map.save_to_html(file_name=data_path+\"/Data processing/Kepler maps/Demand/6pm_demand_count_widths_map.html\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Vehicles Analyzed at 6 PM (Internal): 3331\n",
      "Number of Vehicles Analyzed at 6 PM (External): 1263\n",
      "Number of Vehicles Analyzed at 6 PM (Total): 4594\n",
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813a133d4192456e810b7829b4d1ff63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'External/External Demand': {'index': [0, 1, 2, 3, 4, 5, 7], 'columns': ['CentroidID_O', 'Centrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "path_taz = data_path + \"/Data processing/Auxiliary files/Demand/OD demand/TAZ\"\n",
    "internal_taz = to_gdf(path_taz + \"/Internal_TAZ.shp\")\n",
    "# external_taz = to_gdf(path_taz + \"/External_TAZ.shp\")\n",
    "external_centroids = to_gdf(path_taz + \"/External_centroids.shp\")\n",
    "\n",
    "# Get gravity centers for all TAZs (internal and external)\n",
    "centroid_gravity = {}\n",
    "for i in range(len(internal_taz['geometry'])):\n",
    "    centroid_gravity[internal_taz['CentroidID'][i]] = internal_taz['geometry'][i].centroid\n",
    "for i in range(len(external_centroids['geometry'])):\n",
    "    centroid_gravity[external_centroids['CentroidID'][i]] = external_centroids['geometry'][i]\n",
    "\n",
    "od_demand_path = data_path + \"/Data processing/Temporary exports to be copied to processed data/Demand/OD demand/\" \n",
    "internal_od = pd.read_csv(od_demand_path + \"Internal OD grouped by timestamp.csv\")\n",
    "external_od = pd.read_csv(od_demand_path + \"External OD grouped by timestamp.csv\")\n",
    "\n",
    "# Remove centroids with no demand\n",
    "external_od = external_od[external_od[\"counts\"] != 0]\n",
    "internal_od = internal_od[internal_od[\"counts\"] != 0]\n",
    "\n",
    "# Fix analysis timestep at 6 PM\n",
    "internal_od_6_pm = internal_od[internal_od[\"dt_15\"]==\"18:00\"]\n",
    "external_od_6_pm = external_od[external_od[\"dt_15\"]==\"18:0\"]\n",
    "\n",
    "internal_od_6_pm = internal_od_6_pm.reset_index()\n",
    "external_od_6_pm = external_od_6_pm.reset_index()\n",
    "\n",
    "external_demand = gpd.GeoDataFrame(columns=['CentroidID_O', 'CentroidID_D', \"counts\", 'geometry'])\n",
    "for i in range(len(external_od_6_pm['CentroidID_O'])):\n",
    "    origin_id = external_od_6_pm['CentroidID_O'][i]\n",
    "    dest_id = external_od_6_pm['CentroidID_D'][i]\n",
    "    demand = external_od_6_pm['counts'][i]\n",
    "    external_demand.loc[i] = [origin_id, dest_id, demand, LineString([centroid_gravity[origin_id], centroid_gravity[dest_id]])]\n",
    "\n",
    "internal_demand = gpd.GeoDataFrame(columns=['CentroidID_O', 'CentroidID_D', \"counts\", 'geometry'])\n",
    "internal_external_demand = gpd.GeoDataFrame(columns=['CentroidID_O', 'CentroidID_D', \"counts\", 'geometry'])\n",
    "for i in range(len(internal_od_6_pm['CentroidID_O'])):\n",
    "    origin_id = internal_od_6_pm['CentroidID_O'][i]\n",
    "    dest_id = internal_od_6_pm['CentroidID_D'][i]\n",
    "    demand = internal_od_6_pm['counts'][i]\n",
    "    if origin_id in centroid_gravity and dest_id in centroid_gravity:\n",
    "        if \"ext\" not in origin_id and \"ext\" not in dest_id:\n",
    "            internal_demand.loc[i] = [origin_id, dest_id, demand, LineString([centroid_gravity[origin_id], centroid_gravity[dest_id]])]\n",
    "        else:\n",
    "                internal_external_demand.loc[i] = [origin_id, dest_id, demand, LineString([centroid_gravity[origin_id], centroid_gravity[dest_id]])]\n",
    "\n",
    "print(\"Number of Vehicles Analyzed at 6 PM (Internal):\", internal_od_6_pm.counts.sum())\n",
    "print(\"Number of Vehicles Analyzed at 6 PM (External):\", external_od_6_pm.counts.sum())\n",
    "print(\"Number of Vehicles Analyzed at 6 PM (Total):\", internal_od_6_pm.counts.sum() + external_od_6_pm.counts.sum())\n",
    "\n",
    "fremont_map = KeplerGl(height=600)\n",
    "fremont_map.add_data(data = external_demand[external_demand['counts'] > 2], name=\"External/External Demand\")\n",
    "fremont_map.add_data(data = internal_demand[internal_demand['counts'] > 2], name=\"Internal/Internal Demand\")\n",
    "fremont_map.add_data(data = internal_external_demand[internal_external_demand['counts'] > 2], name=\"Internal/External Demand\")\n",
    "fremont_map.add_data(data = internal_taz, name=\"Internal TAZs\")\n",
    "fremont_map.add_data(data = external_centroids, name=\"External centroids\")\n",
    "\n",
    "fremont_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Street Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points\n",
      "lines\n",
      "multilinestrings\n",
      "multipolygons\n",
      "other_relations\n",
      "1885\n",
      "motorway_junction\n",
      "motorway_junction\n",
      "crossing\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "motorway_junction\n",
      "traffic_signals\n",
      "turning_circle\n",
      "traffic_signals\n",
      "motorway_junction\n",
      "turning_circle\n",
      "turning_circle\n",
      "turning_circle\n"
     ]
    }
   ],
   "source": [
    "import ogr\n",
    "\n",
    "driver=ogr.GetDriverByName('OSM')\n",
    "path_osm = data_path + \"/Raw data (do not touch)/Network/Map/OSM/\"\n",
    "\n",
    "\n",
    "data = driver.Open(path_osm + 'map1111.osm')\n",
    "\n",
    "for i in range(data.GetLayerCount()):\n",
    "    print(data.GetLayerByIndex(i).GetName())\n",
    "    \n",
    "layer = data.GetLayer('points')\n",
    "\n",
    "features=[x for x in layer]\n",
    "print(len(features))\n",
    "\n",
    "data_list=[]\n",
    "i = 0\n",
    "for feature in features:\n",
    "    i = i + 1\n",
    "    data=feature.ExportToJson(as_object=True)\n",
    "    coords=data['geometry']['coordinates']\n",
    "    shapely_geo=Point(coords[0],coords[1])\n",
    "    name=data['properties']['name']\n",
    "    highway=data['properties']['highway']\n",
    "    print(highway)\n",
    "    other_tags=data['properties']['other_tags']\n",
    "    if other_tags and 'amenity' in other_tags:\n",
    "        feat=[x for x in other_tags.split(',') if 'amenity' in x][0]\n",
    "        amenity=feat[feat.rfind('>')+2:feat.rfind('\"')]\n",
    "    else:\n",
    "        amenity=None\n",
    "    data_list.append([name,highway,amenity,shapely_geo])\n",
    "    if i > 20:\n",
    "        break\n",
    "# gdf=gpd.GeoDataFrame(data_list,columns=['Name','Highway','Amenity','geometry'],crs={'init': 'epsg:4326'}).to_crs(epsg=3310)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External TAZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ae824e45fb47f6811ff7c6f55a9e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'External TAZs': {'index': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'columns': ['OBJECTID_1', 'FID_1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "path_taz = data_path + \"/Manual-made dataset (do not touch)/Demand/OD demand/External TAZ/External Centroid zones/\"\n",
    "external_taz = to_gdf(path_taz + \"/ExternalCentroidZones.shp\")\n",
    "\n",
    "fremont_map = KeplerGl(height=600)\n",
    "fremont_map.add_data(data = external_taz, name=\"External TAZs\")\n",
    "fremont_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
